#include <opencv2/core/utility.hpp>
#include <opencv2/tracking.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include <opencv2/video.hpp>
#include "opencv2/calib3d.hpp"
#include <iostream>
#include <cstring>

using namespace std;
using namespace cv;

static Mat image;
static Mat image2;
static Rect2d boundingBox;
static bool paused;
static bool selectObject = false;
static bool startSelection = false;

Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

/*Mat Camera_Matrix = (Mat_<float>(3,3) << 4.3222902118627042e+02, 0., 2.9962806942037730e+02, 0.,
       4.3222902118627042e+02, 2.0483555978703342e+02, 0., 0., 1.);
Mat Distortion_Coeff = (Mat_<float>(5,1) << -4.0584575773895049e-01, 1.2248238739598104e-01,
       4.9198977308994524e-03, -6.0318281458103650e-03,
       -4.3880183708743760e-03);*/

static const char* keys =
{ "{@tracker_algorithm | | Tracker algorithm }"
    "{@video_name      | | video name        }"
    "{@start_frame     |0| Start frame       }" 
    "{@bounding_frame  |0,0,0,0| Initial bounding frame}"};

static void onMouse( int event, int x, int y, int, void* )
{
  if( !selectObject )
  {
    switch ( event )
    {
      case EVENT_LBUTTONDOWN:
        //set origin of the bounding box
        startSelection = true;
        boundingBox.x = x;
        boundingBox.y = y;
        break;
      case EVENT_LBUTTONUP:
        //sei with and height of the bounding box
        boundingBox.width = std::abs( x - boundingBox.x );
        boundingBox.height = std::abs( y - boundingBox.y );
        paused = false;
        selectObject = true;
        break;
      case EVENT_MOUSEMOVE:

        if( startSelection && !selectObject )
        {
          //draw the bounding box
          Mat currentFrame;
          image.copyTo( currentFrame );
          rectangle( currentFrame, Point((int) boundingBox.x, (int)boundingBox.y ), Point( x, y ), Scalar( 255, 0, 0 ), 2, 1 );
          imshow( "Tracking API", currentFrame );
        }
        break;
    }
  }
}

static void help()
{
  cout << "\nThis example shows the functionality of \"Long-term optical tracking API\""
       "-- pause video [p] and draw a bounding box around the target to start the tracker\n"
       "Example of <video_name> is in opencv_extra/testdata/cv/tracking/\n"
       "Call:\n"
       "./tracker <tracker_algorithm> <video_name> <start_frame> [<bounding_frame>]\n"
       "tracker_algorithm can be: MIL, BOOSTING, MEDIANFLOW, TLD\n"
       << endl;

  cout << "\n\nHot keys: \n"
       "\tq - quit the program\n"
       "\tp - pause video\n";
}

int main( int argc, char** argv ){
  CommandLineParser parser( argc, argv, keys );

  String tracker_algorithm = parser.get<String>( 0 );
  String video_name = parser.get<String>( 1 );
  int start_frame = parser.get<int>( 2 );

  if( tracker_algorithm.empty() || video_name.empty() )
  {
    help();
    return -1;
  }

  int coords[4]={0,0,0,0};
  bool initBoxWasGivenInCommandLine=false;
  {
      String initBoundingBox=parser.get<String>(3);
      for(size_t npos=0,pos=0,ctr=0;ctr<4;ctr++){
        npos=initBoundingBox.find_first_of(',',pos);
        if(npos==string::npos && ctr<3){
           printf("bounding box should be given in format \"x1,y1,x2,y2\",where x's and y's are integer cordinates of opposed corners of bdd box\n");
           printf("got: %s\n",initBoundingBox.substr(pos,string::npos).c_str());
           printf("manual selection of bounding box will be employed\n");
           break;
        }
        int num=atoi(initBoundingBox.substr(pos,(ctr==3)?(string::npos):(npos-pos)).c_str());
        if(num<=0){
           printf("bounding box should be given in format \"x1,y1,x2,y2\",where x's and y's are integer cordinates of opposed corners of bdd box\n");
           printf("got: %s\n",initBoundingBox.substr(pos,npos-pos).c_str());
           printf("manual selection of bounding box will be employed\n");
           break;
        }
        coords[ctr]=num;
        pos=npos+1;
      }
      if(coords[0]>0 && coords[1]>0 && coords[2]>0 && coords[3]>0){
          initBoxWasGivenInCommandLine=true;
      }
  }

  //open the capture
  VideoCapture cap;
  cap.open( video_name );
  cap.set( CAP_PROP_POS_FRAMES, start_frame );

  if( !cap.isOpened() )
  {
    help();
    cout << "***Could not initialize capturing...***\n";
    cout << "Current parameter's value: \n";
    parser.printMessage();
    return -1;
  }

  Mat frame;


  paused = true;
  namedWindow( "Tracking API", 1 );
  setMouseCallback( "Tracking API", onMouse, 0 );

  //instantiates the specific Tracker
  Ptr<Tracker> tracker = Tracker::create( tracker_algorithm );
  if( tracker == NULL )
  {
    cout << "***Error in the instantiation of the tracker...***\n";
    return -1;
  }

  //get the first frame
  cap >> frame;

  /*Size imageSize,imageSize2;
        imageSize = frame.size();
        imageSize2 = frame.size();
        Rect ROI = Rect(int(imageSize.width/5), int(imageSize.height*0.22),int(imageSize.width*0.6), int(imageSize.height*0.55));
        Mat temp = frame.clone();
        Mat map1, map2;
        initUndistortRectifyMap(Camera_Matrix, Distortion_Coeff, Mat(),
                                getOptimalNewCameraMatrix(Camera_Matrix, Distortion_Coeff, imageSize, 0.8, imageSize2, 0),
                                imageSize2, CV_16SC2, map1, map2);
        remap(temp, frame, map1, map2, INTER_LINEAR);
        Mat image = frame(ROI);
        frame = image.clone();*/


  // Prabhudev Prakash
  pMOG2 = createBackgroundSubtractorMOG2(5000);
  // Prabhudev Prakash

  frame.copyTo( image );
  if(initBoxWasGivenInCommandLine){
      selectObject=true;
      paused=false;
      boundingBox.x = coords[0];
      boundingBox.y = coords[1];
      boundingBox.width = std::abs( coords[2] - coords[0] );
      boundingBox.height = std::abs( coords[3]-coords[1]);
      printf("bounding box with vertices (%d,%d) and (%d,%d) was given in command line\n",coords[0],coords[1],coords[2],coords[3]);
      rectangle( image, boundingBox, Scalar( 255, 0, 0 ), 2, 1 );
  }
  imshow( "Tracking API", image );

  bool initialized = false;
  int frameCounter = 0;

  for ( ;; )
  {
    if( !paused )
    {
      if(initialized){
          cap >> frame;
          if(frame.empty()){
            break;
          }

          // Image rectify Section

          //pMOG2->apply(frame, frame);
          //blur( frame, frame, Size(8,8) );
          //Canny( frame, frame, 100, 100*2, 3 );
          /*Size imageSize,imageSize2;
          imageSize = frame.size();
          imageSize2 = frame.size();
          Rect ROI = Rect(int(imageSize.width/5), int(imageSize.height*0.22),int(imageSize.width*0.6), int(imageSize.height*0.55));
          Mat temp = frame.clone();
          Mat map1, map2;
          initUndistortRectifyMap(Camera_Matrix, Distortion_Coeff, Mat(),
                                getOptimalNewCameraMatrix(Camera_Matrix, Distortion_Coeff, imageSize, 0.8, imageSize2, 0),
                                imageSize2, CV_16SC2, map1, map2);
          remap(temp, frame, map1, map2, INTER_LINEAR);
          Mat image = frame(ROI);
          frame = image.clone();*/

          // Image Rectify Section
          GaussianBlur(fgMaskMOG2, fgMaskMOG2, cv::Size(5, 5), 2, 2);
          pMOG2->apply(frame, fgMaskMOG2);
          
           

          // Find contours Section

          /*Canny( fgMaskMOG2, fgMaskMOG2, 100, 100*2, 3 );
        
          vector<vector<Point> > contours;
          vector<Vec4i> hierarchy;

          findContours( fgMaskMOG2, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0) );

          Mat drawing = Mat::zeros( fgMaskMOG2.size(), CV_8UC3 );
          for( int i = 0; i< contours.size(); i++ )
          {
          drawContours( drawing, contours, i, cv::Scalar(255,255,255), 2, 8, hierarchy, 0, Point() );
          }

         cout << "number of contours" << contours.size() << endl; */

          // Find Contours section


        // Blob detection section
        SimpleBlobDetector::Params params;

        // Change thresholds
        params.minThreshold = 1;
         params.maxThreshold = 255;

         // Filter by Area.
        params.filterByArea = true;
        params.minArea = 20;

         // Filter by Circularity
         params.filterByCircularity = false;
        params.minCircularity = 0.1;

        // Filter by Convexity
        params.filterByConvexity = false;
        params.minConvexity = 0.87;

        // Filter by Inertia
        params.filterByInertia = false;
         params.minInertiaRatio = 0.2;


        // Storage for blobs
         vector<KeyPoint> keypoints;

         // Set up detector with params
         Ptr<SimpleBlobDetector> detector = SimpleBlobDetector::create(params);   
         detector->detect( fgMaskMOG2, keypoints);

        cout << "Keypoints" << keypoints.size()<< endl; 
        Mat frame_with_keypoints;
        frame_with_keypoints = frame.clone();
        //drawKeypoints( frame, keypoints, frame_with_keypoints, Scalar(0,0,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );
        
         

        for (int i = 0;i < keypoints.size();i++)
        {
         Point top;
         Point bottom;
         top.x = keypoints[i].pt.x - keypoints[i].size/4;
         top.y = keypoints[i].pt.y - keypoints[i].size;
         bottom.x = keypoints[i].pt.x + keypoints[i].size/4;
         bottom.y = keypoints[i].pt.y + keypoints[i].size;
         //top.push_back(keypoints[i].pt - keypoints[i].size/2);
         rectangle(frame_with_keypoints,top,bottom,Scalar(0,0,255),2);  
        }
  
        // Blob Detection section  

        //Prabhudev Prakash
        //Mat temp_Frame;

        //frame.copyTo(temp_Frame,drawing);
        //image = temp_Frame.clone();
        image = frame_with_keypoints.clone();


      }

      if( !initialized && selectObject )
      {
        //initializes the tracker
        if( !tracker->init( image, boundingBox ) )
        {
          cout << "***Could not initialize tracker...***\n";
          return -1;
        }
        initialized = true;
        cout << boundingBox;
      }
      else if( initialized )
      {
        //updates the tracker
        if( tracker->update( image, boundingBox ) )
        {
          rectangle( frame, boundingBox, Scalar( 255, 255, 255 ), 2, 1 );
        }
      }
      imshow( "Tracking API", image );
      frameCounter++;
    }

    char c = (char) waitKey( 2 );
    if( c == 'q' )
      break;
    if( c == 'p' )
      paused = !paused;

  }

  return 0;
}
